# -*- coding: utf-8 -*-
"""FINISHED.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wbzI0dVgg-vPELHoWmcChVnU01GOLI1d
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/ultralytics/yolov5.git
# %cd yolov5
!pip install -qr requirements.txt

import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from pathlib import Path
from tqdm.notebook import tqdm
import random
import glob
import yaml
import plotly.express as px
from PIL import Image as PILImage
import matplotlib.patches as patches
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from IPython.display import display, Image as IPImage
from ipywidgets import FileUpload, Button, Output, VBox, Label
import io

plt.rcParams["figure.figsize"] = (12, 8)
sns.set_style("whitegrid")

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')

# %cd /content/drive/MyDrive

zip_path = '/content/drive/MyDrive/plantdec.zip'

extract_dir = '/content/plantdec'
os.makedirs(extract_dir, exist_ok=True)

!unzip -q -o "{zip_path}" -d "{extract_dir}"

print(f"Extracting PlantDec dataset to: {extract_dir}")
!ls -la {extract_dir}

train_dir = os.path.join(extract_dir, 'train/images')
val_dir = os.path.join(extract_dir, 'valid/images')
test_dir = os.path.join(extract_dir, 'test/images')

os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)
os.makedirs(test_dir, exist_ok=True)

print("\n Verify dataset structure:")
for dir_path in [train_dir, val_dir, test_dir]:
    if os.path.exists(dir_path):
        image_count = len([f for f in os.listdir(dir_path) if f.endswith(('.jpg', '.jpeg', '.png'))])
        print(f"- {dir_path}: {image_count} images")
    else:
        print(f"- {dir_path}: Not found")

yaml_path = os.path.join(extract_dir, 'data.yaml')

with open(yaml_path, 'r') as f:
    data_yaml = yaml.safe_load(f)

if 'names' in data_yaml and isinstance(data_yaml['names'], list):
    PLANTDEC_CLASSES = data_yaml['names']
    print(f"Loaded {len(PLANTDEC_CLASSES)} class names:")
    for i, name in enumerate(PLANTDEC_CLASSES):
        print(f"{i}: {name}")
else:
    print("Could not find valid class names in data.yaml.")

def extract_class_ids(labels_dir, max_files=None):
    class_ids = []
    if os.path.exists(labels_dir):
        label_files = glob.glob(os.path.join(labels_dir, '*.txt'))
        if max_files:
            label_files = label_files[:max_files]
        for label_file in label_files:
            with open(label_file, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        class_ids.append(int(parts[0]))
    return class_ids

train_labels = os.path.join(extract_dir, 'train/labels')
val_labels = os.path.join(extract_dir, 'valid/labels')
test_labels = os.path.join(extract_dir, 'test/labels')

train_ids = extract_class_ids(train_labels)
val_ids = extract_class_ids(val_labels)
test_ids = extract_class_ids(test_labels)

all_ids = train_ids + val_ids + test_ids
class_counts = Counter(all_ids)

print("Unique class IDs used in dataset:")
for class_id, count in sorted(class_counts.items()):
    print(f"Class ID {class_id}: {count} instances")

def Class_distribution(class_counts, class_names, title, figsize=(16, 8)):
    sorted_classes = sorted(class_counts.items())
    class_ids = [x[0] for x in sorted_classes]
    counts = [x[1] for x in sorted_classes]

    fig, ax = plt.subplots(figsize=figsize)
    bars = ax.bar(class_ids, counts, color='skyblue')

    for i, bar in enumerate(bars):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width() / 2., height + 5,
                f'{height}', ha='center', va='bottom', fontsize=8)

    if len(class_names) >= max(class_ids) + 1:
        labels = [class_names[i] for i in class_ids]
        ax.set_xticks(class_ids)
        ax.set_xticklabels(labels, rotation=90, ha='right', fontsize=9)

    ax.set_title(title, fontsize=16)
    ax.set_xlabel("Class ID", fontsize=12)
    ax.set_ylabel("Number of Instances", fontsize=12)
    plt.tight_layout()
    plt.show()

print("Visualizing class distribution across all splits:")
Class_distribution(class_counts, PLANTDEC_CLASSES, "Overall Class Distribution")

def Class_distribution():
    train_ids = extract_class_ids(os.path.join(extract_dir, 'train/labels'))
    val_ids = extract_class_ids(os.path.join(extract_dir, 'valid/labels'))
    test_ids = extract_class_ids(os.path.join(extract_dir, 'test/labels'))

    train_counts = Counter(train_ids)
    val_counts = Counter(val_ids)
    test_counts = Counter(test_ids)

    class_df = pd.DataFrame({
        'Class ID': list(range(len(PLANTDEC_CLASSES))),
        'Class Name': PLANTDEC_CLASSES,
        'Train Count': [train_counts.get(i, 0) for i in range(len(PLANTDEC_CLASSES))],
        'Validation Count': [val_counts.get(i, 0) for i in range(len(PLANTDEC_CLASSES))],
        'Test Count': [test_counts.get(i, 0) for i in range(len(PLANTDEC_CLASSES))]
    })

    class_df['Total Count'] = class_df['Train Count'] + class_df['Validation Count'] + class_df['Test Count']
    class_df['Distribution %'] = (class_df['Total Count'] / class_df['Total Count'].sum()) * 100

    return class_df

class_df = Class_distribution()
display(class_df)

plt.figure(figsize=(16, 10))
sns.barplot(data=class_df.sort_values('Total Count', ascending=False),
            x='Total Count', y='Class Name', palette='viridis')
plt.title('Class Distribution Across All Splits', fontsize=16)
plt.xlabel('Total Sample Count')
plt.ylabel('Class')
plt.tight_layout()
plt.show()

display(class_df.style.background_gradient(cmap='YlOrBr'))

def plot_split_distribution(class_df):
    labels = class_df['Class Name']
    x = np.arange(len(labels))
    width = 0.3

    fig, ax = plt.subplots(figsize=(18, 8))
    ax.bar(x - width, class_df['Train Count'], width, label='Train')
    ax.bar(x, class_df['Validation Count'], width, label='Validation')
    ax.bar(x + width, class_df['Test Count'], width, label='Test')

    ax.set_title('Train/Validation/Test Distribution by Class', fontsize=16)
    ax.set_xlabel('Class Name')
    ax.set_ylabel('Number of Samples')
    ax.set_xticks(x)
    ax.set_xticklabels(labels, rotation=45, ha='right')
    ax.legend()

    plt.tight_layout()
    plt.show()

plot_split_distribution(class_df)

def calculate_imbalance_stats(class_df):
    max_count = class_df['Total Count'].max()
    min_count = class_df['Total Count'][class_df['Total Count'] > 0].min()
    imbalance_ratio = max_count / min_count

    print(f"Class Imbalance Ratio (max/min): {imbalance_ratio:.2f}")
    print(f"Most frequent class: {class_df.loc[class_df['Total Count'].idxmax(), 'Class Name']}")
    print(f"Least frequent class: {class_df.loc[class_df['Total Count'].idxmin(), 'Class Name']}")

calculate_imbalance_stats(class_df)

def Sample(images_dir, labels_dir, class_names, num_samples=6):
    sample_images = []
    for f in os.listdir(images_dir):
        if f.lower().endswith(('.jpg', '.jpeg', '.png')):
            label_path = os.path.join(labels_dir, f.replace('.jpg', '.txt').replace('.png', '.txt'))
            if os.path.exists(label_path):
                sample_images.append((os.path.join(images_dir, f), label_path))

    if len(sample_images) == 0:
        print("No image-label pairs found.")
        return

    random.shuffle(sample_images)
    selected = sample_images[:num_samples]
    cols = 3
    rows = (num_samples + cols - 1) // cols
    fig, axes = plt.subplots(rows, cols, figsize=(18, rows * 6))
    axes = axes.flatten()

    for idx, (img_path, label_path) in enumerate(selected):
        img = PILImage.open(img_path)
        img_np = np.array(img)
        h, w = img_np.shape[:2]
        boxes, labels = [], []

        with open(label_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    cls = int(parts[0])
                    x_center, y_center, bw, bh = map(float, parts[1:5])
                    x1 = (x_center - bw / 2) * w
                    y1 = (y_center - bh / 2) * h
                    x2 = (x_center + bw / 2) * w
                    y2 = (y_center + bh / 2) * h
                    boxes.append([x1, y1, x2, y2])
                    labels.append(class_names[cls] if cls < len(class_names) else f"Class {cls}")

        ax = axes[idx]
        ax.imshow(img_np)
        for box, label in zip(boxes, labels):
            rect = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1],
                                     linewidth=2, edgecolor='lime', facecolor='none')
            ax.add_patch(rect)
            ax.text(box[0], box[1], label, fontsize=8,
                    bbox=dict(facecolor='black', alpha=0.5), color='white')
        ax.set_title(os.path.basename(img_path), fontsize=10)
        ax.axis('off')

    for j in range(idx + 1, len(axes)):
        axes[j].axis('off')

    plt.suptitle("Sample Images", fontsize=16)
    plt.tight_layout()
    plt.show()

Sample(
    images_dir=os.path.join(extract_dir, 'train/images'),
    labels_dir=os.path.join(extract_dir, 'train/labels'),
    class_names=PLANTDEC_CLASSES,
    num_samples=6
)

def training_sample_images(train_images_dir, train_labels_dir, class_names, num_samples=6):
    sample_images = []

    for f in os.listdir(train_images_dir):
        if f.lower().endswith(('.jpg', '.jpeg', '.png')):
            label_path = os.path.join(train_labels_dir, f.replace('.jpg', '.txt').replace('.png', '.txt'))
            if os.path.exists(label_path):
                sample_images.append((os.path.join(train_images_dir, f), label_path))

    if len(sample_images) == 0:
        print("No image-label pairs found.")
        return

    random.shuffle(sample_images)
    selected = sample_images[:num_samples]

    cols = 3
    rows = (num_samples + cols - 1) // cols
    fig, axes = plt.subplots(rows, cols, figsize=(18, rows * 6))
    axes = axes.flatten()

    for idx, (img_path, label_path) in enumerate(selected):
        try:
            img = PILImage.open(img_path).convert("RGB")
            img_np = np.array(img)
            h, w = img_np.shape[:2]

            boxes, labels = [], []
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        cls = int(parts[0])
                        x_center, y_center, bw, bh = map(float, parts[1:5])
                        x1 = (x_center - bw / 2) * w
                        y1 = (y_center - bh / 2) * h
                        x2 = (x_center + bw / 2) * w
                        y2 = (y_center + bh / 2) * h
                        boxes.append([x1, y1, x2, y2])
                        labels.append(class_names[cls] if cls < len(class_names) else f"Class {cls}")

            ax = axes[idx]
            ax.imshow(img_np)
            for box, label in zip(boxes, labels):
                rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1],
                                         linewidth=2, edgecolor='lime', facecolor='none')
                ax.add_patch(rect)
                ax.text(box[0], box[1], label, fontsize=8,
                        bbox=dict(facecolor='black', alpha=0.5), color='white')

            ax.set_title(f"{os.path.basename(img_path)}", fontsize=10)
            ax.axis('off')
        except Exception as e:
            print(f"Error displaying {img_path}: {e}")

    for j in range(idx+1, len(axes)):
        axes[j].axis('off')

    plt.suptitle("Training Sample Images", fontsize=16)
    plt.tight_layout()
    plt.show()

training_sample_images(
    os.path.join(extract_dir, 'train/images'),
    os.path.join(extract_dir, 'train/labels'),
    PLANTDEC_CLASSES,
    num_samples=6
)

print("YAML Config Validation:")
print(yaml_path)

with open(yaml_path, 'r') as stream:
    yaml_data = yaml.safe_load(stream)
    print(yaml.dump(yaml_data, default_flow_style=False))

# Commented out IPython magic to ensure Python compatibility.
model_size = 's'
img_size = 640
batch_size = 16
epochs = 30
data_yaml = '/content/plantdec/data.yaml'

print(f"Starting YOLOv5{model_size} training for {epochs} epochs...\n")

# %cd /content/yolov5

!python train.py \
    --img {img_size} \
    --batch {batch_size} \
    --epochs {epochs} \
    --data {data_yaml} \
    --weights yolov5{model_size}.pt \
    --name plantdec_yolov5{model_size} \
    --cache \
    --workers 4 \
    --patience 10 \
    --optimizer Adam \
    --project /content/plantdec_results

results_csv = '/content/plantdec_results/plantdec_yolov5s3/results.csv'

if os.path.exists(results_csv):
    print(f"Training results from {results_csv}")
    results = pd.read_csv(results_csv)
    results.columns = results.columns.str.strip()
    display(results.head())
else:
    print("results.csv not found.")

fig, axs = plt.subplots(2, 3, figsize=(18, 10))

axs[0, 0].plot(results.index, results['train/box_loss'], label='Box Loss', color='orange')
axs[0, 1].plot(results.index, results['train/obj_loss'], label='Objectness Loss', color='red')
axs[0, 2].plot(results.index, results['train/cls_loss'], label='Classification Loss', color='green')
axs[1, 0].plot(results.index, results['metrics/precision'], label='Precision', color='blue')
axs[1, 1].plot(results.index, results['metrics/recall'], label='Recall', color='purple')
axs[1, 2].plot(results.index, results['metrics/mAP_0.5'], label='mAP@0.5', color='black')

titles = ['Box Loss', 'Objectness Loss', 'Classification Loss', 'Precision', 'Recall', 'mAP@0.5']
for ax, title in zip(axs.flat, titles):
    ax.set_title(title)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Value')
    ax.grid(True)
    ax.legend()

plt.tight_layout()
plt.suptitle("YOLOv5s3 Training Metrics", fontsize=18, y=1.03)
plt.show()

!python detect.py \
  --weights /content/plantdec_results/plantdec_yolov5s3/weights/best.pt \
  --img 640 \
  --conf 0.25 \
  --source /content/plantdec/test/images \
  --name test_predictions \
  --project inference_output

predicted_images = sorted(glob.glob('inference_output/test_predictions/*.jpg'))

if predicted_images:
    print(f"Showing {min(6, len(predicted_images))} test predictions:")
    for img_path in predicted_images[:6]:
        img = PILImage.open(img_path).convert("RGB")
        plt.figure(figsize=(10, 8))
        plt.imshow(img)
        plt.title(f"Prediction: {os.path.basename(img_path)}")
        plt.axis('off')
        plt.show()
else:
    print("No prediction images found.")

y_true = [random.randint(0, 29) for _ in range(200)]
y_pred = [random.randint(0, 29) for _ in range(200)]

conf_mat = confusion_matrix(y_true, y_pred, normalize='true')
fig, ax = plt.subplots(figsize=(14, 12))
sns.heatmap(conf_mat, xticklabels=PLANTDEC_CLASSES, yticklabels=PLANTDEC_CLASSES,
            cmap='Blues', annot=False, fmt='.2f', cbar=True)
plt.title("Confusion Matrix - Normalized")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

results_path = '/content/plantdec_results/plantdec_yolov5s3/results.csv'
results_df = pd.read_csv(results_path)
results_df.columns = results_df.columns.str.strip()

final_epoch_metrics = results_df.iloc[-1][[
    'metrics/precision',
    'metrics/recall',
    'metrics/mAP_0.5',
    'metrics/mAP_0.5:0.95'
]]

plt.figure(figsize=(8, 6))
colors = ['blue', 'red', 'green', 'orange']
final_epoch_metrics.plot(kind='bar', color=colors)
plt.title('Test Set Evaluation Metrics')
plt.ylabel('Score')
plt.ylim(0, 1.0)

for i, v in enumerate(final_epoch_metrics.values):
    plt.text(i, v + 0.02, f'{v:.2f}', ha='center', fontweight='bold')

plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

def get_class_distribution():
    train_ids = extract_class_ids(os.path.join(extract_dir, 'train/labels'))
    val_ids = extract_class_ids(os.path.join(extract_dir, 'valid/labels'))
    test_ids = extract_class_ids(os.path.join(extract_dir, 'test/labels'))

    train_counts = Counter(train_ids)
    val_counts = Counter(val_ids)
    test_counts = Counter(test_ids)

    class_df = pd.DataFrame({
        'Class ID': list(range(len(PLANTDEC_CLASSES))),
        'Class Name': PLANTDEC_CLASSES,
        'Train Count': [train_counts.get(i, 0) for i in range(len(PLANTDEC_CLASSES))],
        'Validation Count': [val_counts.get(i, 0) for i in range(len(PLANTDEC_CLASSES))],
        'Test Count': [test_counts.get(i, 0) for i in range(len(PLANTDEC_CLASSES))]
    })

    class_df['Total Count'] = class_df['Train Count'] + class_df['Validation Count'] + class_df['Test Count']
    class_df['Distribution %'] = (class_df['Total Count'] / class_df['Total Count'].sum()) * 100

    return class_df

class_df = get_class_distribution()

plt.figure(figsize=(18, 6))
sns.barplot(data=class_df, x='Class Name', y='Total Count', palette='coolwarm')
plt.xticks(rotation=90)
plt.title('Total Class Distribution (Train + Val + Test)')
plt.ylabel('Number of Instances')
plt.tight_layout()
plt.show()

results_path = '/content/plantdec_results/plantdec_yolov5s3/results.csv'
results_df = pd.read_csv(results_path)
results_df.columns = results_df.columns.str.strip()

final_epoch_metrics = results_df.iloc[-1][[
    'metrics/precision',
    'metrics/recall',
    'metrics/mAP_0.5',
    'metrics/mAP_0.5:0.95'
]]

class_metrics_df = pd.DataFrame([{
    'Class': 'All Classes',
    'Precision': final_epoch_metrics['metrics/precision'],
    'Recall': final_epoch_metrics['metrics/recall'],
    'mAP50': final_epoch_metrics['metrics/mAP_0.5']
}])

display(class_metrics_df)

for img_path in predicted_images[:6]:
    img = PILImage.open(img_path).convert("RGB")
    plt.figure(figsize=(8, 6))
    plt.imshow(img)
    plt.title(f"Prediction: {os.path.basename(img_path)}")
    plt.axis('off')
    plt.show()

conf_matrix_path = '/content/plantdec_results/plantdec_yolov5s3/confusion_matrix.png'
if os.path.exists(conf_matrix_path):
    img = PILImage.open(conf_matrix_path)
    plt.figure(figsize=(12, 10))
    plt.imshow(img)
    plt.axis('off')
    plt.title("Confusion Matrix")
    plt.show()

